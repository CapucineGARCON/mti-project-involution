{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-JbZ6fkoUs-"
      },
      "source": [
        "# Experimentations\n",
        "## Experimentations on MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKUjDRnnoUtD"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "- ~Create and checkout a branch for your work (`git checkout -b YOUR_BRANCH_NAME`)~\n",
        "- ~Create a copy of this template and name it however you want (e.g. `YOUR_NAME.ipynb`).~\n",
        "- ~Change the title according to what scenario you are testing.~\n",
        "- ~In the \"involution\" part, replace the existing model with the relevant model.~\n",
        "- ~Create as many cells as you deem necessary for the experiments (explain your use case, comparison with convolution or other networks, results, etc.)~\n",
        "- Remove this cell and every \"TODO\" comment.\n",
        "- When you are done, commit your changes. Make sure you are only committing changes on the file you created! (you can check with `git status`)\n",
        "- Push your changes on the repo (`git push --set-upstream origin YOUR_BRANCH_NAME`).\n",
        "- Create a pull request to the `main` branch so that everyone can read your code before we merge it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO12352FoUtE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from involution import Involution\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import visualkeras # for NN visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PREtUKCE3sOo"
      },
      "source": [
        "## Utility function to train models and display results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0wF6A9GqUKn"
      },
      "outputs": [],
      "source": [
        "def train_model(model, x_train, x_test, y_train, y_test, batch_size, epochs):\n",
        "  # Trains the model\n",
        "  # Putting the output of model.fit in a variable \"history\" gives access to information on accuracy and loss\n",
        "  start = time.time()\n",
        "  history = model.fit(x=x_train, \n",
        "            y=y_train, \n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs, \n",
        "            validation_data=(x_test, y_test),\n",
        "            verbose=1)\n",
        "  end = time.time()\n",
        "  execution_time = end - start\n",
        "\n",
        "  return history, execution_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITKvgvZOxGMu"
      },
      "outputs": [],
      "source": [
        "def display_results(history):\n",
        "  fig, ax = plt.subplots(1,2, figsize=(15,8))\n",
        "\n",
        "  ax[0].plot(history.history['accuracy'], label='training accuracy')\n",
        "  ax[0].plot(history.history['val_accuracy'], label='validation accuracy')\n",
        "  ax[0].grid()\n",
        "  ax[0].legend()\n",
        "  ax[0].set_title('Accuracy vs. Epochs')\n",
        "  ax[0].set_xlabel('# Epochs')\n",
        "\n",
        "  ax[1].plot(history.history['loss'], label='training loss')\n",
        "  ax[1].plot(history.history['val_loss'], label='validation loss')\n",
        "  ax[1].grid()\n",
        "  ax[1].legend()\n",
        "  ax[1].set_title('Loss vs. Epochs')\n",
        "  ax[1].set_xlabel('# Epochs')\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5Bf1wVqp2QD"
      },
      "source": [
        "## MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbbzhnFwp2fK"
      },
      "outputs": [],
      "source": [
        "(x_raw_train_mnist, y_train_mnist), (x_raw_test_mnist, y_test_mnist) = mnist.load_data() # downloads the MNIST dataset (handwritten numbers)\n",
        "\n",
        "# Scales images to the [0,1] range and expands the dimensions so that it has shape (28, 28, 1)\n",
        "x_train_mnist = np.expand_dims(x_raw_train_mnist.astype(\"float32\") / 255, -1) \n",
        "x_test_mnist = np.expand_dims(x_raw_test_mnist.astype(\"float32\") / 255, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4D0LsrlqVw9"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure\n",
        "id_img = np.random.randint(0, len(x_train_mnist)) # takes a random image from the dataset\n",
        "\n",
        "plt.imshow(x_raw_train_mnist[id_img], cmap='gray') # imshow an image from the dataset\n",
        "plt.suptitle(\"Representation of a \"+str(y_train_mnist[id_img])+\" in MNIST Dataset\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5I7opdAqHtg"
      },
      "source": [
        "## Convolution\n",
        "\n",
        "CNN inspired by Lecun et al in http://yann.lecun.com/exdb/publis/pdf/lecun-iscas-10.pdf.\n",
        "\n",
        "Model available at https://keras.io/examples/vision/mnist_convnet/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U5XHT_9s77x"
      },
      "source": [
        "### Convolution model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtd1KUMqJTD"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "\n",
        "cnn = keras.Sequential( # definition of the CNN\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)), # images of size 28x28 pixels, with only 1 channel (greyscale)\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), # convolution layer: dot products with the weights, and activation function\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)), # pooling layer: downsampling, reduces the size of the representation\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(), # flatten layer: converts the data into a 1-D feature vector to feed it to the final layers\n",
        "        layers.Dropout(0.5), # dropout layer: drops part of the data to avoid overfitting\n",
        "        layers.Dense(num_classes, activation=\"softmax\"), # dense layer: computes the result\n",
        "    ]\n",
        ")\n",
        "\n",
        "cnn.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualkeras.layered_view(cnn, draw_volume=False, legend=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVl5QNyE2NJB"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 10\n",
        "\n",
        "cnn_history, cnn_time = train_model(cnn, x_train_mnist, x_test_mnist, y_train_mnist, y_test_mnist, batch_size, epochs)\n",
        "print(\"The classification accuracy for the CNN %.2f\"%(100*np.max(cnn_history.history['val_accuracy']))+\" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4_U3BxD4Ksn"
      },
      "outputs": [],
      "source": [
        "display_results(cnn_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuEdP-CXoUtF"
      },
      "source": [
        "## Involution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kbNfbV3xQbI"
      },
      "outputs": [],
      "source": [
        "inn = keras.Sequential( # definition of the CNN\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)), # images of size 28x28 pixels, with only 1 channel (greyscale)\n",
        "        Involution(channel=3,group_number=1,kernel_size=3,stride=1,reduction_ratio=2),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)), # pooling layer: downsampling, reduces the size of the representation\n",
        "        Involution(channel=3,group_number=1,kernel_size=3,stride=1,reduction_ratio=2),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(), # flatten layer: converts the data into a 1-D feature vector to feed it to the final layers\n",
        "        layers.Dropout(0.5), # dropout layer: drops part of the data to avoid overfitting\n",
        "        layers.Dense(num_classes, activation=\"softmax\"), # dense layer: computes the result\n",
        "    ]\n",
        ")\n",
        "\n",
        "inn.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTta1A8OoUtH"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 10\n",
        "\n",
        "inn_history, inn_time = train_model(inn, x_train_mnist, x_test_mnist, y_train_mnist, y_test_mnist, batch_size, epochs)\n",
        "print(\"The classification accuracy for the INN %.2f\"%(100*np.max(inn_history.history['val_accuracy']))+\" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRkQBk7x40bs"
      },
      "outputs": [],
      "source": [
        "inn.summary()\n",
        "visualkeras.layered_view(inn, draw_volume=False, legend=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7I4dEU64-Wu"
      },
      "outputs": [],
      "source": [
        "display_results(inn_history)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "experiments-hadrien.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "34ff3397c474938b265d2f4b45024e5465249fab18e07736c9a068b37b408800"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('python-all': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

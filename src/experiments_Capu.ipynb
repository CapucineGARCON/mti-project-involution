{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sg-itVcn3AC"
      },
      "source": [
        "# Experimentations\n",
        "## [INN & CNN with Fashion MNIST]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL9piIAxn3AF"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "- Create and checkout a branch for your work (`git checkout -b YOUR_BRANCH_NAME`)\n",
        "- Create a copy of this template and name it however you want (e.g. `YOUR_NAME.ipynb`).\n",
        "- Change the title according to what scenario you are testing.\n",
        "- In the \"involution\" part, replace the existing model with the relevant model.\n",
        "- Create as many cells as you deem necessary for the experiments (explain your use case, comparison with convolution or other networks, results, etc.).\n",
        "- Remove this cell and every \"TODO\" comment.\n",
        "- When you are done, commit your changes. Make sure you are only committing changes on the file you created! (you can check with `git status`)\n",
        "- Push your changes on the repo (`git push --set-upstream origin YOUR_BRANCH_NAME`).\n",
        "- Create a pull request to the `main` branch so that everyone can read your code before we merge it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy_AQcMloU3-"
      },
      "outputs": [],
      "source": [
        "# cloning the github repo in order to have the file involution.py\n",
        "\n",
        "!git clone https://github.com/CapucineGARCON/mti-project-involution.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y38NyjEvzpfD"
      },
      "outputs": [],
      "source": [
        "%mv /content/mti-project-involution/src/involution.py /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHfusVj0n3AG"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from involution import Involution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYoALCbCn_rl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python import keras \n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, Dropout, MaxPooling2D, Conv2D\n",
        "\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "#import visualkeras\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaqhdAVtprsP"
      },
      "source": [
        "## Datasat importation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use the Fashion MNIST Dataset which is a famous dataset of Zalando's article images consisting in a training set of 60,000 images and a test set of 10,000 images.\n",
        "Each observation is a 28 x 28 grayscale image, associated with a label from 10 fashion classes."
      ],
      "metadata": {
        "id": "jthH-ViLF-Aa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6m19XMKpozF"
      },
      "outputs": [],
      "source": [
        "# Import du dataset Fashion MNIST\n",
        "((X_train, Y_train), (X_test, Y_test)) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bAY67LYsP-T"
      },
      "outputs": [],
      "source": [
        "# Normalization between 0 and 1\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siU6CjBUv76e"
      },
      "outputs": [],
      "source": [
        "# Resizing images (28,28,1)\n",
        "X_train = np.expand_dims(X_train.astype(\"float32\"), -1) \n",
        "X_test = np.expand_dims(X_test.astype(\"float32\"), -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TabYw0ISyr5Q"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe1M1GRR8-Iu"
      },
      "outputs": [],
      "source": [
        "class_names = ['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOg_81IG67DJ"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_train[20].reshape(28,28),cmap = 'gray' )\n",
        "plt.xlabel(class_names[Y_train[20]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzedia9B0ZqE"
      },
      "source": [
        "## Convolution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters \n",
        "epochs = 40\n",
        "batch_size = 20"
      ],
      "metadata": {
        "id": "N5fm8qugIQTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualkeras.layered_view(inn, draw_volume=False, legend=True)"
      ],
      "metadata": {
        "id": "PytukibzCG8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "convolution_model = tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', input_shape = (28,28,1), padding = 'same'),\n",
        "          tf.keras.layers.MaxPool2D((2,2)),\n",
        "          tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
        "          tf.keras.layers.MaxPool2D((2,2)),\n",
        "          tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "          tf.keras.layers.Dense(10),])\n",
        "\n",
        "\n",
        "convolution_model.summary()\n",
        "\n",
        "convolution_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "pGrF41nmHxq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLzVxA7o0c7P"
      },
      "outputs": [],
      "source": [
        "#def convolution_model():\n",
        "#  model = Sequential()\n",
        "#  model.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', input_shape = (28,28,1), padding = 'same'))\n",
        "#  model.add(MaxPooling2D((2,2)))\n",
        "#  model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
        "#  model.add(MaxPooling2D((2,2)))\n",
        "#  model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
        "#  model.add(Flatten())\n",
        "#  model.add(Dense(64, activation = 'relu'))\n",
        "#  model.add(Dense(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxfpntgc5Fxc"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "train_convolution = convolution_model.fit(X_train, Y_train, epochs = epochs, validation_data= (X_test, Y_test))\n",
        "time = time.time() - start_time\n",
        "print(time)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training time = 6 minutes"
      ],
      "metadata": {
        "id": "oje3jekCTAhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of the loss for the training set and the validation set"
      ],
      "metadata": {
        "id": "qu8ghXilJ8aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_convolution.history[\"loss\"], label=\"Training loss\")\n",
        "plt.plot(train_convolution.history[\"val_loss\"], label=\"Validation loss\")\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Loss function')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TrhsvSTKJw5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that it is not necessary to train our model on 40 epochs because we are going to have overfitting. Indeed, we can see that our validation loss is incresing after 5 epochs because the model is starting to overfit on the training set."
      ],
      "metadata": {
        "id": "Eif6DioEL-U_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of the accuraccy for the training and validation set"
      ],
      "metadata": {
        "id": "3uZiEdsUKEo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_convolution.history[\"accuracy\"], label=\"Training accuracy\")\n",
        "plt.plot(train_convolution.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u154mQBMJ7TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov9TtVDcn3AI"
      },
      "source": [
        "## Involution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XOIgm-Gn3AJ"
      },
      "outputs": [],
      "source": [
        "involution_model = tf.keras.models.Sequential([\n",
        "    Involution(channel=3,group_number=1,kernel_size=3,stride=1,reduction_ratio=2),\n",
        "    tf.keras.layers.ReLU(name=\"relu1\"),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    Involution(channel=3,group_number=1,kernel_size=3,stride=1,reduction_ratio=2),\n",
        "    tf.keras.layers.ReLU(name=\"relu2\"),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    Involution(channel=3,group_number=1,kernel_size=3,stride=1,reduction_ratio=2),\n",
        "    tf.keras.layers.ReLU(name=\"relu3\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10),\n",
        "])\n",
        "\n",
        "involution_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzAyE_aEn3AK"
      },
      "outputs": [],
      "source": [
        "# Involution Neural Network training\n",
        "start_time = time.time()\n",
        "\n",
        "train_involution = involution_model.fit(X_train, Y_train, epochs = epochs, validation_data= (X_test, Y_test))\n",
        "\n",
        "time = time.time() - start_time\n",
        "print(time)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training time is 11 minutes for the involution Neural Network."
      ],
      "metadata": {
        "id": "Eso0BUZ3Q4Gu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAdK0uat5Iew"
      },
      "outputs": [],
      "source": [
        "involution_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXsSHH9szHtR"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_involution.history[\"loss\"], label=\"Training loss\")\n",
        "plt.plot(train_involution.history[\"val_loss\"], label=\"Validation loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss function')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqevDpXc1ovJ"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_involution.history[\"accuracy\"], label=\"Training accuracy\")\n",
        "plt.plot(train_involution.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison between CNN and INN"
      ],
      "metadata": {
        "id": "_pVLRfWgRZXe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hL1TcLm6n3AL"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_involution.history[\"loss\"], label=\"Inv loss\")\n",
        "plt.plot(train_convolution.history[\"loss\"], label=\"Conv loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss function')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Q05cRHn3AN"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_involution.history[\"accuracy\"], label=\"Inv accuracy\")\n",
        "plt.plot(train_convolution.history[\"accuracy\"], label=\"Conv accuracy\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mambJV_4TU90"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "experiments-Capu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "34ff3397c474938b265d2f4b45024e5465249fab18e07736c9a068b37b408800"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('python-all': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}